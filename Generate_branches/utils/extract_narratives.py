"""
This module provides utilities for extracting narrative content from JSON files
generated by the FSM-LLM-Narrative system and saving it in a readable text format.
"""

import os
import json
import glob
import argparse
import re
from typing import Dict, List, Optional, Tuple, Any

def _format_emotion_pool(pool: List[Dict[str, Any]]) -> str:
    """Helper function to format an emotion pool list."""
    lines = []
    for entry in pool:
        trigger = entry.get("trigger_condition") or "(Always)"
        goal = entry.get("goal", "N/A")
        lines.append(f"    - Trigger: {trigger}\n      Goal: {goal}")
    return "\n".join(lines)

def _format_subtask_to_text(subtask: Dict[str, Any]) -> str:
    """Helper function to format a single subtask dictionary into readable text."""
    content = []
    content.append(f"Title: {subtask.get('title', 'N/A')}")
    content.append(f"Subtask ID: {subtask.get('subtask_id', 'N/A')}")
    content.append(f"Description: {subtask.get('description', 'N/A')}")
    content.append(f"Dialogue:\n{subtask.get('dialogue', 'N/A')}")

    # New fields extraction
    environment = subtask.get('environment')
    if environment:
        content.append(f"\nEnvironment: {environment}")

    interactive_env_objects = subtask.get('interactive_environment_objects')
    if interactive_env_objects:
        content.append("\nInteractive Environment Objects:")
        if isinstance(interactive_env_objects, list):
            for i, obj in enumerate(interactive_env_objects, 1):
                obj_name = obj.get('name', 'Unnamed Object')
                obj_cost = obj.get('action_point_cost', 'N/A')
                content.append(f"  {i}. {obj_name} (Cost: {obj_cost})")
        else:
            content.append(f"  Data: {interactive_env_objects}") # Fallback for unexpected format

    interactive_npcs = subtask.get('interactive_npc')
    if interactive_npcs:
        content.append("\nInteractive NPCs:")
        if isinstance(interactive_npcs, list):
            for i, npc in enumerate(interactive_npcs, 1):
                npc_name = npc.get('name', f'NPC {i}')
                content.append(f"  {i}. Name: {npc_name}")
                additional_conditions = npc.get('additional_conditions')
                if additional_conditions:
                    content.append(f"     Additional Conditions: {additional_conditions}")
                npc_goal = npc.get('goal')
                if npc_goal:
                    content.append(f"     Goal: {npc_goal}")
                emotion_pool = npc.get('emotion_pool')
                if emotion_pool:
                    content.append("     Emotion Pool:")
                    content.append(_format_emotion_pool(emotion_pool)) # Reuse existing helper
        else:
            content.append(f"  Data: {interactive_npcs}") # Fallback

    subtask_key_questions = subtask.get('key_questions')
    if subtask_key_questions:
        content.append("\nKey Questions (Specific to this Subtask):")
        if isinstance(subtask_key_questions, list):
            for i, q_data in enumerate(subtask_key_questions, 1):
                q_id = q_data.get('id', 'N/A')
                q_content = q_data.get('content', q_data.get('english', 'N/A'))
                content.append(f"  {i}. (ID: {q_id}) {q_content}")
        else:
            content.append(f"  Data: {subtask_key_questions}") # Fallback

    scene_end_ref = subtask.get('scene_end_state_reference')
    if scene_end_ref:
        content.append("\nScene End State Reference:")
        if isinstance(scene_end_ref, dict):
            for key, value in scene_end_ref.items():
                content.append(f"  {key}: {value}")
        else:
            content.append(f"  Data: {scene_end_ref}") # Fallback

    player_options = subtask.get('player_options', [])
    if player_options:
        content.append("\nPlayer Options:")
        for i, option in enumerate(player_options, 1):
            content.append(f"  {i}. {option}")

    npc_reactions = subtask.get('npc_reactions', {})
    if npc_reactions:
        content.append("\nNPC Reactions:")
        for npc, reaction in npc_reactions.items():
            content.append(f"  {npc}: {reaction}")
            
    npc_emotion_pools = subtask.get('npc_emotion_pools', {})
    if npc_emotion_pools:
        content.append("\nNPC Emotion Pools:")
        for npc, pool in npc_emotion_pools.items():
             if isinstance(pool, list):
                content.append(f"  {npc}:")
                content.append(_format_emotion_pool(pool))
             else: # Handle cases where it might not be a list (e.g., fallback)
                 content.append(f"  {npc}: {pool}")


    return "\n".join(content) + "\n"


def extract_narratives_from_task_folder(task_folder: str, output_file: Optional[str] = None) -> Optional[str]:
    """
    Extracts narrative content from JSON files in a specific task folder, formats it,
    orders it by layer, and saves it to a text file.

    Args:
        task_folder: Path to the task folder (containing Scripted_subtask_* and Subtask_branches_* subfolders).
        output_file: Optional path for output text file. If None, creates a file in the task folder.

    Returns:
        Path to the created text file, or None if extraction fails.
    """
    if not os.path.isdir(task_folder):
        print(f"Error: Task folder does not exist: {task_folder}")
        return None

    folder_name = os.path.basename(task_folder)
    if not output_file:
        output_file = os.path.join(task_folder, f"{folder_name}_narrative.txt")

    narrative_data = {} # Store extracted data keyed by layer and type
    key_questions_list = []
    task_name = "Unknown Task" # Fallback task name

    scripted_folders = glob.glob(os.path.join(task_folder, "Scripted_subtask_*"))
    branches_folders = glob.glob(os.path.join(task_folder, "Subtask_branches_*"))

    # --- Process Scripted Subtasks ---
    if scripted_folders:
        scripted_folder = scripted_folders[0]
        scripted_files = glob.glob(os.path.join(scripted_folder, "scripted_subtask_layer*_*.json"))
        
        # Sort files by layer number naturally
        scripted_files.sort(key=lambda f: int(re.search(r'layer(\d+)', f).group(1)) if re.search(r'layer(\d+)', f) else 0)

        for file_path in scripted_files:
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                
                # Extract task_info and key questions once
                if not key_questions_list and 'task_info' in data:
                    task_info = data.get('task_info', {})
                    task_name = task_info.get('name', task_info.get('scene_name', folder_name))
                    # Prefer key questions from task_info if available
                    if 'key_questions' in task_info and isinstance(task_info['key_questions'], list):
                         key_questions_list = [q.get('english', q.get('content', 'Invalid Question Format')) 
                                               for q in task_info['key_questions']]
                    elif 'transitioning_questions' in data.get('task_info',{}): # Fallback
                         key_questions_list = data['task_info']['transitioning_questions']


                raw_response = data.get("raw_response", "{}")
                
                # Clean potential markdown fences
                cleaned_response = raw_response.strip()
                if cleaned_response.startswith("```json"):
                    cleaned_response = cleaned_response[7:] # Remove ```json
                if cleaned_response.endswith("```"):
                    cleaned_response = cleaned_response[:-3] # Remove ```
                cleaned_response = cleaned_response.strip() # Remove any extra whitespace

                # Attempt to parse the actual LLM response JSON inside cleaned_response
                try:
                    subtask_json = json.loads(cleaned_response)
                    if isinstance(subtask_json, dict):
                         layer = subtask_json.get('layer')
                         subtask_id = subtask_json.get('subtask_id', 'unknown_scripted')
                         if layer is not None:
                             if layer not in narrative_data: narrative_data[layer] = {'scripted': None, 'alternatives': []}
                             narrative_data[layer]['scripted'] = (subtask_id, _format_subtask_to_text(subtask_json))
                    else:
                         print(f"Warning: Parsed raw_response in {os.path.basename(file_path)} is not a dictionary.")

                except json.JSONDecodeError:
                    print(f"Warning: Could not parse raw_response JSON in {os.path.basename(file_path)}. Raw content: {cleaned_response[:100]}...")
                except Exception as e:
                    print(f"Warning: Error processing raw_response in {os.path.basename(file_path)}: {e}")

            except Exception as e:
                print(f"Error reading or processing file {file_path}: {e}")
    else:
        print(f"Warning: No 'Scripted_subtask_*' folder found in {task_folder}")

    # --- Process Subtask Branches (Alternatives) ---
    if branches_folders:
        branches_folder = branches_folders[0]
        branch_files = glob.glob(os.path.join(branches_folder, "subtask_branches_layer*_*.json"))
        
        # Sort files by layer number naturally
        branch_files.sort(key=lambda f: int(re.search(r'layer(\\d+)', f).group(1)) if re.search(r'layer(\\d+)', f) else 0)

        for file_path in branch_files:
            file_basename = os.path.basename(file_path) # For clearer logging
            try:
                with open(file_path, 'r', encoding='utf-8') as f: # Added encoding
                     data = json.load(f)

                raw_response = data.get("raw_response", "[]") # Default to empty list string
                
                # Clean potential markdown fences
                cleaned_response = raw_response.strip()
                if cleaned_response.startswith("```json"):
                    cleaned_response = cleaned_response[7:] # Remove ```json
                if cleaned_response.endswith("```"):
                    cleaned_response = cleaned_response[:-3] # Remove ```
                cleaned_response = cleaned_response.strip() # Remove any extra whitespace

                # Attempt to parse the actual LLM response JSON array inside cleaned_response
                try:
                    branches_json = json.loads(cleaned_response)
                    if isinstance(branches_json, list):
                        for branch_index, branch in enumerate(branches_json): # Use index for logging
                             if isinstance(branch, dict):
                                 layer = branch.get('layer')
                                 subtask_id = branch.get('subtask_id', f'unknown_alternative_idx_{branch_index}') # Default ID using index
                                 if layer is not None:
                                     if layer not in narrative_data: narrative_data[layer] = {'scripted': None, 'alternatives': []}
                                     # Check if the branch dict looks valid before formatting
                                     if 'title' in branch and 'dialogue' in branch:
                                         narrative_data[layer]['alternatives'].append((subtask_id, _format_subtask_to_text(branch)))
                                     else:
                                         print(f"Warning: Skipping branch at index {branch_index} in {file_basename} due to missing 'title' or 'dialogue'.")
                             else:
                                  print(f"Warning: Item at index {branch_index} in branches list is not a dictionary in {file_basename}.")
                    else:
                         print(f"Warning: Parsed raw_response in {file_basename} is not a list as expected for branches.")


                except json.JSONDecodeError as json_err:
                     # Provide more detail on JSON decode error
                     print(f"Warning: Could not parse raw_response JSON in {file_basename}. Error: {json_err}. Raw content: {cleaned_response[:150]}...")
                except Exception as e:
                    print(f"Warning: Unexpected error processing raw_response in {file_basename}: {e}")

            except Exception as e:
                print(f"Error reading or processing file {file_path}: {e}")
    else:
        print(f"Warning: No 'Subtask_branches_*' folder found in {task_folder}")

    # --- Assemble the final text output ---
    output_content = [f"Narrative Summary for Task: {task_name}"]
    output_content.append(f"Source Folder: {folder_name}")
    output_content.append("=" * 80 + "\n")

    # Add Key Questions
    output_content.append("KEY QUESTIONS")
    output_content.append("-" * 80)
    if key_questions_list:
        for i, q in enumerate(key_questions_list, 1):
            output_content.append(f"{i}. {q}")
    else:
        output_content.append("No key questions found or extracted.")
    output_content.append("\n" + "=" * 80 + "\n")
    
    # Add narrative content sorted by layer
    sorted_layers = sorted(narrative_data.keys())
    
    for layer in sorted_layers:
        layer_data = narrative_data[layer]
        
        # Add Scripted Subtask for the layer
        if layer_data.get('scripted'):
            subtask_id, formatted_text = layer_data['scripted']
            output_content.append(f"LAYER {layer} - SCRIPTED SUBTASK ({subtask_id})")
            output_content.append("-" * 80)
            output_content.append(formatted_text)
            output_content.append("\n" + "-" * 80 + "\n")
        else:
            output_content.append(f"LAYER {layer} - SCRIPTED SUBTASK")
            output_content.append("-" * 80)
            output_content.append("(No scripted subtask data found for this layer)\n")
            output_content.append("\n" + "-" * 80 + "\n")


        # Add Alternatives for the layer, sorted by ID
        alternatives = sorted(layer_data.get('alternatives', []), key=lambda item: item[0]) # Sort by subtask_id
        if alternatives:
             output_content.append(f"LAYER {layer} - ALTERNATIVES")
             output_content.append("-" * 80)
             for i, (subtask_id, formatted_text) in enumerate(alternatives):
                 output_content.append(f"Alternative {i+1} ({subtask_id}):")
                 output_content.append(formatted_text)
                 if i < len(alternatives) - 1:
                     output_content.append("\n---\n") # Separator between alternatives
             output_content.append("\n" + "=" * 80 + "\n") # End of layer alternatives
        # else: # Optional: Add message if no alternatives found
        #     output_content.append(f"LAYER {layer} - ALTERNATIVES")
        #     output_content.append("-" * 80)
        #     output_content.append("(No alternative branch data found for this layer)\n")
        #     output_content.append("\n" + "=" * 80 + "\n")


    # --- Write to file ---
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(output_content))
        print(f"Narrative summary saved to: {output_file}")
        return output_file
    except Exception as e:
        print(f"Error writing output file {output_file}: {e}")
        return None


def find_task_folders(base_dir: str = "Generate_branches/data") -> List[str]:
    """
    Find all task folders in the base directory.
    
    Args:
        base_dir: Base directory to search in, defaults to "Generate_branches/data"
        
    Returns:
        List of paths to task folders
    """
    # Create base directory if it doesn't exist
    if not os.path.exists(base_dir):
        return []
    
    # Find all directories that might be task folders
    potential_task_folders = []
    for item in os.listdir(base_dir):
        item_path = os.path.join(base_dir, item)
        if os.path.isdir(item_path):
            # Check if it has subdirectories matching the pattern
            if (glob.glob(os.path.join(item_path, "Scripted_subtask_*")) or
                glob.glob(os.path.join(item_path, "Subtask_branches_*"))):
                potential_task_folders.append(item_path)
    
    return potential_task_folders


def list_tasks(base_dir: str = "Generate_branches/data") -> None:
    """
    List all available task folders.
    
    Args:
        base_dir: Base directory to search in, defaults to "Generate_branches/data"
    """
    task_folders = find_task_folders(base_dir)
    
    if not task_folders:
        print(f"No task folders found in {base_dir}")
        return
    
    print(f"Found {len(task_folders)} task folder(s):")
    for i, folder in enumerate(task_folders, 1):
        folder_name = os.path.basename(folder)
        print(f"{i}. {folder_name}")


def main():
    """Main entry point for the command-line utility."""
    parser = argparse.ArgumentParser(description='Extract narrative content from task folders')
    parser.add_argument('--task', '-t', help='Task folder name or path (if omitted, will list available tasks)')
    parser.add_argument('--output', '-o', help='Output file path (optional)')
    parser.add_argument('--data-dir', '-d', default="Generate_branches/data", 
                        help='Base data directory (default: Generate_branches/data)')
    
    args = parser.parse_args()
    
    # If no task specified, list available tasks
    if not args.task:
        list_tasks(args.data_dir)
        return
    
    # Determine the task folder path
    if os.path.isdir(args.task):
        # Direct path was provided
        task_folder = args.task
    else:
        # Task name provided, find the folder in data_dir
        # Simple match for now, assumes unique task name prefix
        possible_folders = glob.glob(os.path.join(args.data_dir, f"{args.task}*"))
        task_folders = [f for f in possible_folders if os.path.isdir(f)]
        
        if not task_folders:
            print(f"Error: Task folder starting with '{args.task}' not found in {args.data_dir}")
            return
        elif len(task_folders) > 1:
            print(f"Warning: Multiple task folders found starting with '{args.task}'. Using the first one: {os.path.basename(task_folders[0])}")
            task_folder = task_folders[0]
        else:
            task_folder = task_folders[0]

    # Extract narratives
    output_file = extract_narratives_from_task_folder(task_folder, args.output)
    
    if output_file:
        print("Extraction complete.")
    else:
        print("Extraction failed.")

if __name__ == "__main__":
    main() 