"""
Processes task folders generated by the FSM-LLM-Narrative system,
extracts the clean JSON content from the 'raw_response' field of log files,
and saves it to a parallel structure under a 'Middle_data' directory.
"""

import os
import json
import glob
import argparse
import re
from typing import Dict, List, Optional, Any

# Default base directory for the processed data
DEFAULT_MIDDLE_DATA_DIR = "Middle_data"

def clean_and_parse_raw_response(raw_response_str: str) -> Optional[Any]:
    """Cleans markdown fences and parses JSON string."""
    if not isinstance(raw_response_str, str):
        print(f"Warning: raw_response is not a string ({type(raw_response_str)}), skipping parsing.")
        return None
        
    cleaned_response = raw_response_str.strip()
    if cleaned_response.startswith("```json"):
        cleaned_response = cleaned_response[7:]
    if cleaned_response.endswith("```"):
        cleaned_response = cleaned_response[:-3]
    cleaned_response = cleaned_response.strip()

    if not cleaned_response:
        # print("Warning: Cleaned response is empty, skipping parsing.")
        return None # Return None for empty strings after cleaning

    try:
        return json.loads(cleaned_response)
    except json.JSONDecodeError as e:
        print(f"Warning: JSONDecodeError - {e}. Content: {cleaned_response[:150]}...")
        return None
    except Exception as e:
        print(f"Warning: Unexpected error parsing JSON - {e}. Content: {cleaned_response[:150]}...")
        return None


def process_task_folder_to_middle(task_folder: str, middle_data_base: str):
    """
    Processes a single task folder, extracting raw responses and saving clean JSON.

    Args:
        task_folder: Path to the source task folder (e.g., data/TaskName_Timestamp).
        middle_data_base: Path to the base directory for output (e.g., Middle_data).
    """
    if not os.path.isdir(task_folder):
        print(f"Error: Source task folder not found: {task_folder}")
        return

    task_folder_basename = os.path.basename(task_folder)
    target_task_dir = os.path.join(middle_data_base, task_folder_basename)

    print(f"Processing task folder: {task_folder_basename}")
    print(f"Target directory: {target_task_dir}")

    # Define source subdirectories to process
    source_subdirs_patterns = [
        os.path.join(task_folder, "Scripted_subtask_*"),
        os.path.join(task_folder, "Subtask_branches_*")
    ]

    files_processed_count = 0
    files_written_count = 0

    for pattern in source_subdirs_patterns:
        source_subdirs = glob.glob(pattern)
        for source_subdir in source_subdirs:
            if not os.path.isdir(source_subdir):
                continue
            
            source_subdir_basename = os.path.basename(source_subdir)
            target_subdir = os.path.join(target_task_dir, source_subdir_basename)
            
            print(f"  Processing subdirectory: {source_subdir_basename}")
            
            source_files = glob.glob(os.path.join(source_subdir, "*.json"))
            
            if not source_files:
                 print(f"    No .json files found in {source_subdir_basename}")
                 continue

            for source_file_path in source_files:
                files_processed_count += 1
                source_file_basename = os.path.basename(source_file_path)
                target_file_path = os.path.join(target_subdir, source_file_basename)
                
                try:
                    # print(f"    Reading: {source_file_basename}")
                    with open(source_file_path, 'r', encoding='utf-8') as f_in:
                        log_data = json.load(f_in)
                    
                    raw_response = log_data.get("raw_response")
                    
                    if raw_response is None:
                        print(f"    Warning: No 'raw_response' field found in {source_file_basename}, skipping.")
                        continue

                    parsed_data = clean_and_parse_raw_response(raw_response)

                    if parsed_data is not None:
                        # Ensure target directory exists
                        os.makedirs(target_subdir, exist_ok=True)
                        
                        # Write the parsed JSON data
                        with open(target_file_path, 'w', encoding='utf-8') as f_out:
                            json.dump(parsed_data, f_out, indent=2, ensure_ascii=False)
                        # print(f"      Successfully wrote: {target_file_path}")
                        files_written_count += 1
                    # else: # Already printed warning in clean_and_parse
                    #     print(f"      Failed to parse/clean raw_response from {source_file_basename}")

                except json.JSONDecodeError:
                    print(f"    Error: Could not decode JSON from source file {source_file_basename}. Skipping.")
                except Exception as e:
                    print(f"    Error processing file {source_file_basename}: {e}")

    print(f"Finished processing {task_folder_basename}. Processed {files_processed_count} files, wrote {files_written_count} files to {target_task_dir}.")


# Reuse find_task_folders logic (or similar) if needed for CLI
def find_task_folders(base_dir: str) -> List[str]:
    """Find all potential task folders in the base directory."""
    if not os.path.exists(base_dir) or not os.path.isdir(base_dir):
        return []
    potential_task_folders = []
    for item in os.listdir(base_dir):
        item_path = os.path.join(base_dir, item)
        if os.path.isdir(item_path):
            # Check criteria: presence of specific subfolders
            if (glob.glob(os.path.join(item_path, "Scripted_subtask_*")) or
                glob.glob(os.path.join(item_path, "Subtask_branches_*"))):
                potential_task_folders.append(item_path)
    return potential_task_folders

# --- Main Execution Block ---
def main():
    parser = argparse.ArgumentParser(
        description="Extract clean JSON responses from task log files into a parallel 'Middle_data' structure."
    )
    parser.add_argument(
        'task', 
        help="Source task folder path (e.g., data/TaskName_Timestamp) or just the TaskName_Timestamp part."
    )
    parser.add_argument(
        '--data-dir', 
        '-d', 
        default="Generate_branches/data", 
        help="Base directory containing the source task folders (default: Generate_branches/data)."
    )
    parser.add_argument(
        '--middle-dir', 
        '-m', 
        default=DEFAULT_MIDDLE_DATA_DIR,
        help=f"Base directory to write the output structures (default: {DEFAULT_MIDDLE_DATA_DIR})."
    )

    args = parser.parse_args()

    # Determine the full source task folder path
    source_task_folder = args.task
    if not os.path.isdir(source_task_folder):
        # If not a direct path, assume it's a name within data_dir
        source_task_folder = os.path.join(args.data_dir, args.task)
        if not os.path.isdir(source_task_folder):
             # Try finding it more dynamically if the exact name wasn't given
             possible_folders = glob.glob(os.path.join(args.data_dir, f"{args.task}*"))
             task_folders_found = [f for f in possible_folders if os.path.isdir(f)]
             if not task_folders_found:
                 print(f"Error: Cannot find source task folder '{args.task}' directly or within '{args.data_dir}'.")
                 return 1 # Indicate error
             elif len(task_folders_found) > 1:
                 print(f"Warning: Multiple folders match '{args.task}' in '{args.data_dir}'. Using the first: {os.path.basename(task_folders_found[0])}")
                 source_task_folder = task_folders_found[0]
             else:
                  source_task_folder = task_folders_found[0]


    # Ensure the base middle_data directory exists
    middle_data_base_path = args.middle_dir
    try:
        os.makedirs(middle_data_base_path, exist_ok=True)
        print(f"Ensured base output directory exists: {middle_data_base_path}")
    except OSError as e:
        print(f"Error: Could not create base output directory '{middle_data_base_path}': {e}")
        return 1 # Indicate error

    # Process the specified task folder
    process_task_folder_to_middle(source_task_folder, middle_data_base_path)
    
    return 0 # Indicate success

if __name__ == "__main__":
    import sys
    sys.exit(main()) 